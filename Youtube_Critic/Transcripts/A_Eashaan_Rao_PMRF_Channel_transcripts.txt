Channel Name: A_Eashaan_Rao_PMRF_Channel
Channel ID: UCxPXEVGN4u9CZj8giOuWCnQ

--- Combined Transcripts ---

--- Video 1 ---
Video ID: Gwl5lsNvSG8
Video Title: noc23_cs110: Deep Learning (Session 5) : Mathematical Intuition for BackPropagation (with code)

Transcript:
okay awesome uh so good evening everyone my name is shishandra and this is the fifth interaction session for us uh so as of now a few of you or I think most of you are following uh the content with respect to from last three four weeks uh so we will say this session will be the kind of uh duck kind of the last in the terms of basic basic things that's why I want to introduce the mathematics aspect to it uh till this session we will be using all the basic uh we will be discussing what we have discussed the basic building blocks and what we are going to discuss till now is going to be used for the upcoming uh negative architecture like the words that you might heard of recurrent neural network conversational Network and all that right so we will start with the basic aspect of this and we will continue uh this uh we'll continue with this book building on this block you will get some pre intuition uh or pre-assemptions which will be following towards the building of the actual neural network okay that being said this session will be typically math heavy uh or some derivation part with respect to it where uh we were going to discuss the black back propagation because that is something it we eventually which you're going to see in all the other learning algorithm from now onwards whatever the complex learning algorithm will be there you're going to see from there so I just want to re uh recap that part once maybe in an r in an r and off follow that I will share the code with you where instead of writing the code the code always has been written and we will just discuss how we can code code it and how you can play with that code and try to understand the notebook on your own in a better way while playing with that below okay so that is the pre context of this so the mostly it's uh we will discussing with mostly the partial derivatives and directed with this book to the how updating of the weights and biases going to happen mostly we will talk in terms of the weights the same principle will be applied to biases as well okay uh so if you have any other questions for doubts please put that in the chat and from time to time I will see in the chat box okay so that if uh so if this context has been set clearly let's revise few things before starting off uh the actual math part with respect to this okay so typically uh we have a neural network this is a okay let me so this is a neural network okay I'll just write it as nn a new network will have few things that is X1 X2 X3 this is called as input layer these two layers are called as hidden layers and this third out the topmost layer which is called as output layer and all these things are the the nodes you can say one node is basically a sigma neuron okay w means paid vector so w when we are saying W1 W2 and W3 it means it is a weight Vector so this will be W 1 1 uh W 1 2 W 1 3 like that so it has total nine to nine kind of thing so each row Arrow considered as a one weight Vector with respect to this and each node have its own bias okay so B2 B1 b3s are also Vector where we talk about B1 B12 and B one three so let's assume as of now for uh understanding one is the first layer and in the first layer first neuron is the bias first layer second neuron is the bias of uh the second neuron and first layer third is the third bias okay this is a typical uh new network structure is look going to look like now uh in a typical learning scenario that you have seen as of now uh in a simple settings it will be like I will have some pre-initialized weights W1 W one two w one three uh like that W one four W one five kind of like this okay so this weights and bias will be pre-initialized randomly okay so this initialization Here Is Random now what is happening is in each neuron there's a two phase so let me take another color so so let's assume this blue highlighted in the first layer let's see this it is called as pre-activation pre-activation mode and let's say yellow part the yellow highlighting it we call as activation function okay now what we are doing in pre-activation basically we are trying to do simply like uh W 1 1 into X1 plus bias 1 right so simple w x kind of this uh dot product plus bias we are adding it in in the terms of pre-activation layer now in the activation function we're basically using the sigmoid function because it's eventually this is a sigma neuron all these things are Sigma neuron okay so activation function is sigmoid function right so sigmat function you might know one uh divided by one uh one plus e raised to W X plus b kind of thing right so let's denote it so A1 is called as preactivation H1 is called as activation for that particular layer similarly A2 is a preactivation with respect to uh the H1 as input so H1 when we say H1 H1 is also a vector which will call as h11 h12 h13 that is first layer first neuron first layer second neuron first layer third neuron like that similarly A2 A2 is also uh three activation values for with respect to that now what we are doing what you have seen in feed forward Network basically that you have some weights you apply in certain formula and after applying certain formula you apply a sigma neuron functionality here and you get some value so let's suppose uh you're getting for H1 let's say 0.8 0.9.1 kind of like this right so this values you are getting as uh after certain computation now what you are going to do again this W2 weights will be there for where these three neurons will be go down to second hidden layer and try to connect with each of the Hidden layer right now so what is happening that uh neuron 1 from layer 1 is going to uh going pass through to all the neurons of layer 2 hidden layer 2 right so once you're trying to get it you are going to now here instead of X1 as an input here you will give 0.8 of h11 as an input and again you're going to pass pass through this and again this some pre-activation activation will come into picture like this like how you see in a hidden layer now once is this hidden layers are done something interesting happen interesting happen in terms of output layer where output layer will also contains the uh pre-activation aspect and activation aspect right but interesting part will be this pre-activation will be same as what we have seen right so it will be uh it will be one uh so it will be like w let me change the color so it will be like w 3 1 into h 2 1 something like that and B3 some kind of preactivation function will be written here in pre-activation but in the activation function you have heard now you already have the term of uh uh cross entropy uh not cross entropy you might heard of uh the terms of exponentiality right so where in the classification aspect when you are going to do the classification aspect uh there you going to put the word what is exact word uh okay so you will try to calculate the entropy functional with respect to it so you will say that with this log of Y cap or log of 1 minus y cap right for the class 0 and considering it's a classification problem you you're defining the function based on the last neuron so here whatever the sigmoid function that you have carried as activation function here it will come down to loss function with respect to it okay now whatever the loss function come into which you get calculate some value so let me go down so let's say in the output layer you get some values okay let's say it says y cap buy y not typical Y is a truth value this is ground truth okay or you say ground truth and by cap you get as a probability distribution let's say if is a binary classification 0 between 0 and 1 class y can be 0 and 1 but here you can say 0.7.3 that is class 1 has a probability of 0.7 and 0 has class 0.3 so this is called as predicted value okay so this is called as predicted value right now you have till here everything is fine so feed forward Network what we have seen that you will calculate like this okay feed forward Network calculate like this so what it will do again you will do a something called as Epoch again the weights will be changed so change weights will be changed with respect to W let's say w 1 2 W 1 2 minus this is called learning rate learning trade dot Delta W12 this is a typical update uh updated equation right now we have seen that there's some formula with respect to uh with respect to how to calculate this Delta uh W2 and you might heard that Delta W 2 will be calculated with with the perspective gradient descent as a word right and automatic mathematical aspect will come into pitch right now the question we should arise in in a typical thing the natural question should be arise that now when you sing the term epoch and you are updating this where it's somehow using calculating uh using using the term called gradient descent how are you actually updating it are you again going back to starting back to zero so that means now here I found some loss at the output layer some losses there so did am I going directly back to the again to the near the the first input layer and I am updating W1 W2 W3 kind of like that I will update this layer then I will update the second hidden layer then I will update the output layer I am again going back from bottom to up or I am am I going from top to bottom so these are two different aspects right so how actually we're updating it that's a natural question that we have to ask right so question is how are we updating the weights that means how we are bidding is using gradient design you get some values now weight values are there you don't have problem now the question is are you going bottom to top just like how the uh how the how this uh what we say uh typical field forward network is happening so are you changing the weights from bottom to top or are you going from or top to bottom that means how your calculation is actually happening are you going from output layer to the input layer or input layer to Output layer right this is the typically two scenarios are coming to picture and we are actually coding it also right here the actual concept of back publication will come into picture why back publication because we know that once we have a loss function based on the loss function we'll update our uh our parameters right so this is typically fine like we know that that after we check the loss function we update our W and B and once uh these two vectors are uh two vectors or matrices are upgraded again we are going to back again going to check that what is the loss function so it is a to and fro thing right it's a two and four is happening but how the back proportion come into picture this is what the discussion is going to be look like okay now before going to this and telling about how we can do that to give instead of directly giving intuition with how the back propagation come into picture in simple terms you can just tell that yeah it is happening that from bottom to input this is the first option that is in back propagation you are going to update the weights by looking back so you will look back output layer again you're going back to the first little layer uh again you will go uh again you will go back and then you'll find okay there are more layers that needs to be computed so you're going to check that and till the point this is the input layer suppose this is input layer so you will trace it back Okay so this kind of thing which is General intuition this is like this is what happening in in the actual practical scenario okay so before building up the intuition with respect to the how actually you're going from backward and why do you need to go by backward why can't you so once you know that the weight vectors of all the in between layers and have updated why can't you directly jump and okay now you say that W Vector has been updated B Vector has been updated for all the layers now let me go back again from the start and again look at the input layer and again adjust the value why that is not feasible or why you need to look at why this is a more preferable method okay we will look into that okay so as of now for back propagation you are updating the weights you are doing it already from the starting it's just that now we are bringing this concept more concretely more precisely uh into the picture okay so if this this is how if this is convinced to you that uh from output layer you're going down to input layer and updating the weights by looking each layer one by one this is a back propagation in a simple sense okay now we will see how mathematically we can do that okay now let's assume that uh so we will take step by step thing so what first we will do we will take this uh let's suppose we have to update the w22 vector okay so what w22 is like so w 2 2 will be like this is a second layer okay second layer second neuron second neuron from first layer okay so this is a kind of terminology I will again repeat back but I just to give you overview what we are going to do we will take this as a simple thing we will we will see how using back propagation we'll just try to update this simple one vector that is in this case w22 Okay once we get that like this we will see that how it is going to influence the final output the output Vector okay once we able to do this once able to convince that okay this way direct updated and this is how it's it's forming a relation with respect to it now what we have to see another part is if I am going backward I have to trace back certain aspects that means let's suppose I have to uh play with I have to update the vector w131 okay now what I am finding that from X1 so I'm going to this third neuron of the Hidden layer and from there I have to update the weights of both the neuron and the output layer right so I have multiple paths so I have two parts are there so how am I I'm actually updating if I am going from top to bottom how I am actually updating these two values that means if you're going to see this you will assume naturally you will assume that there are lots of computation is happening so how can we reduce that part okay that is something we are going to see and once we see it mathematically we'll we will again properly we will try to discuss with respect to how the back propagation will work in the context of uh in a simple scenario in this case okay so we will see this part and we will try to give you proper normal intuition without any mathematics we will just establish that why back propagation is useful to us okay so this is a context and let's start with again foreign here okay so before giving that aspect also into the picture I will just try to introduce you few Concepts uh which should be handy to you in the terms of calculus okay so that is basically called as uh derivatives partial derivatives and the chain rule so let's look into it so some basic concept I want to just introduce you says that when we are just trying to do certain computation you should not be uh you shouldn't it should not go over to your head so even if you're not able to get it fully you will get some basic understanding of what is actually happening during the mathematical derivation okay so basic calculation we are looking from the derivative perspective okay so uh in a simple setting so we have seen some function already like you have seen EA raised to X as one of the functions x square as one of the function you might have seen one plus e raised to minus X now X can be anything let's say these are the some common function you have seen now if you have to take a derivative with respect to that now y derivative because when what derivation is actually doing that it is try to break down your whole function to simple simple steps okay in the basic basic functions and when the whole this model is you're going to see it will it will be a combination of very composite functions so what do you mean by composite function that is it it is a combination of multiple functions okay so let's say if you like W1 H1 plus B1 this is one function then W 2 h 2 plus B2 so I'm just trying to give a simplified answer uh analogy of what composite function should look like okay and now when you're trying to update a vector of Delta W you have to you have to make a derivation with respect to this and this kind of complex function will come into picture and over the period of time lot of complex functions will come with temperature so that's why derivatives is taken just to find some basic minimum value for this Delta W which we can utilize to update the actual weight vectors okay now this is the so these are the sum of the common functionalities you can do into picture now for this directly if we have write e raised to X by DX you can if you know derivative it directly adds output like this uh so if we have d x square this x square is a function and you'd uh doing the derivation with respect to X as a variable you can get as a value of 2x kind of thing okay uh maybe in this case if before going this let's say if you want if your function is f x is 1 by X okay so what uh so derivation of DX by 1 by X is 1 by x square okay so these are some basic derivation now what we have to see the concept of chain rule okay so our task would be to bring our functions to certain basic terminologies like this and then compute its derivation that because that will help us to and give a better understanding how do we do that let's take this as an example uh add it as a box so assume we have a function called X now if you do negative operation to this it will convert to minus X again it will convert if you apply exponential operation to it you will make it E raised to minus X okay now if you have let me add here if you add addition of one so you can write 1 plus 2 e raised to minus X okay as a node okay and if you again apply inverse function over it it will become 1 plus e raised 1 plus a 1 divided by 1 plus e raised to minus X so you can see from X as an input I have to plus so many operation that is I have to make it first negative then I have to apply for exponential then I have to add 1 to make it this one plus e raised to minus 6 and then I have to apply inverse function to make the final output like this right so this is a concept of chaining chaining of function now chaining of derivation which will be like that's chained rule of in derivation means like what I will do I will just name them into different kind of functions so let's say instead of writing minus X maybe I will write A1 e raised to minuses I will write A2 this is a A3 and this will let's say A4 okay now let's assume this is actually our y function this is the output function that we are having this is let's assume this is Sigma function and and I want to take out d y by DX that is derivative of like this okay so what I can do I can divide this d y into multiple chunks of the individual functions how can I do that so what I will do is let's say your A4 is like this right instead of A4 that's right my right like y now what I can do is d y by A3 I will do so that means I'll just write it down so D3 by D2 and D2 by D1 sorry A3 A3 by A2 A2 by A1 and a 1 by X DX okay okay so this is a kind of chain rule you can see now if you can see if I just this same thing the d y by DX I just convert into multiple functions of A1 A2 A3 A4 kind of thing okay the same way the chaining of function is happening right how you convert X to minus X to e raised to minus x 2 1 plus e raised to minus X Plus 1 divided by 1 plus equals to minus X okay the same thing we have done here in we have just expanded it why this need to expand because it will help us understanding uh taking derivation in a much easier way what do I mean by it so let's say eighth from the above it is like A3 is equal to e raised to minus X right now if I'm and Y is 1 plus e raised to minus X so I can just directly substitute it like one y equal to a 1 by 1 by A3 okay so if this is there I know that if I just do uh 1 by A3 and if I did uh take a derivation of that process book to A3 it will come back to 1 minus 1 by a A3 Square just like how we have seen it here so how function f by X it comes down to minus 1 by x square similarly what I did instead of directly taking doing this I have substitute 1 plus e raised to x square into as a A3 as a substitute variable I applied it here and I know the value of a 1 by A3 as a typical function because the some primary derivatives of that I did it and I got this as one value so this part is done so let me tight it down so this part is done now I have to do for A3 with respect to ax now let me change it here again okay let me do now A2 was e raised to minus X see A2 is e raised to minus X okay now e raised to minus X is there and are A3 was 1 plus e raised to minus X okay so what I can do substitute is like A3 is equal to 1 plus A2 simple if I now this became more simpler than calculating this okay now once it becomes simpler what I can do I can differentiate A3 with respect to A2 because I have A2 as a variable so if I apply a derivative with respect to S since 1 is constant one is constant will be 0 and a with respect to A2 anything differentiate by A2 it will be 1 right so differentiation of d x by DX is equal to 1 so it will also become like one so so in this okay sorry so again here I got the value as 1 for d y by A3 is called I got at minus A3 Square okay now my I have remaining two that is d a 2 by A1 and D A 1 by X so if you can now if you can get a little bit idea now A2 foreign X okay you can take it like this better okay so once you do this now we have e raised to x minus into picture so I can just write it as A2 equal to e raised to a now I know the derivation of this because it's basic one of the basic derivation so uh uh simple uh derivative function value so I will when I if I try to derivate A2 with respect to A1 let me write a 1 here so I will get the same value as e raised to A1 okay now last last most so A1 is basically X okay uh let's say a0 or A1 is basically X now I have to just differentiate A1 with respect to X okay because x x are same so I just trying to keep everything the same terminology so I am just getting since I am doing since the minus is there the value will be minus 1. okay so let's tie up together what we have seen as of now that for deriving finding a derivative of this you can just do directly because of is a combination of multiple function so what we did we derive it d y with respect to A3 now A3 was 1 plus e raised to minus X then we derive A3 with respect to A2 now A2 was e raised to x minus X so we just take just one single component from that now A2 with respect to A1 now e raised now in E raised to minus X also we have one component called minus X so we taken out like that and then a 1 by D raised to X so this is a proper chaining Rule and if you want to see that we since we want to achieve d y by DX even if you cut down like this you will eventually find DX by DXL d y by DX as well okay so this is the thing now let's put all the value together so we found from d y by d a 3 bus minus A3 1 by A3 now d a 3 by D A 2 it was one value and D A 2 by A1 is like e raised to A1 and D by ax is minus 1 so this is the value we got and if you put substitute all the values together here so let's put it here so A1 is minus X so e raised to minus X and this minus minus will cancel and A3 was so a square not a cube so it will take 1 plus e raised to minus Square okay so this is a typical chaining of a derivative okay I if you're not able to understand I would uh I want you to after this class and for better understanding please understand the chain rule of derivative okay for a simple derivative how we by forcating of one function into multiple States once we do that we can apply this such that we can get to be we can get to the basic functionalities where we can do proper proper derivative rules okay so this is a chain rule of derivative if this is something you able to get down and get down this as a rule this part we are going to apply in towards all of our towards all the finding of uh green descent that you're going to do for that so for each hidden layer activation function free activation function we are actually going to apply partial derivatives what is partial derivative partial derivative is simply like so in a simple partial derivative in a okay let me say what is derivative and derivative you have only one function with one variable that is e raised to X you have one variable only right but what if you have a function call f x Y which is called x square plus y Square okay then you can't apply DX directly because there are two variables are there right so what you will do you will up you will do this f x with respect to uh fx5 with respect to partial derivative of X Plus partial derivative of x square access to y sorry not plus into so this is a kind of chain rule that you are having so you're just trying to bifurcate that one time I will do partial derivative with respect to X variable and one time I will do partial derivative with respect to Y variable so this this function is called dou okay so this is the partial derivative with respect to it now if you unders uh this is something we are going to apply everywhere why because now when you say w as a weight Vector okay it has multiple values so let's say w 1 1 W 1 2 W 1 3 W 2 1 W 2 2 W 2 3. W 3 1 W 3 2 W 3 3 okay so let's assume these are our new network of three uh in neuron in each layer for our topmost is output layer bottom is input layer and the uh in this one middle one is hidden layer right when we are trying to calculate the weight vectors because we have to update each and every Vector each and every every Vector is is related to the value of x and bias is related to that so each each component of a w Vector is actually in itself is a function right so it's itself is a combination of multiple other factors like input and the biases that's why when we are going to calculate and update the vectors we have to calculate each and every component of this weight Vector okay so what so we will show for one example one or two example will show how for you updating one single Vector huh what what how much calculation we can do and how we can at the end of the day we can try to summarize it okay since lot of calculation is going to happen as you have seen earlier in the chain rule itself for simple function call 1 1 raised to 1 plus e raised to minus X you have you have to divide the function to at least four type four different types you have to make a small small part of that right to get to the output final output of e raised to minus X uh plus 1 plus e raised to minus X whole square right to get this value you have to you have to divide the this function simple one one simple function into four four parts similarly when you're going to do compute for weights and biasing it will be much more complex function because uh it has contained Sigma neurons at the end of the day so that it will be it has lot of competition to come into picture okay so once you get understanding of how how partial derivative mean by how your how you're taking derivation with respect to each and every single variable which is involvement of function that is one thing and the chain rule of derivative once you uh you understand these two concepts we can start off by to compute how to how after getting a loss function our value okay how you can go back and update a one single loss Vector with uh one single weight Vector with respect to that once we get this understanding we will go back to see that how multiple uh weight vectors can be operated in simultaneously okay okay so let's start with one vector that is let's try to understand that how to update this W1 to w212 okay so what w212 means 2 means the this is the first layer this is second layer okay and this is the third layer so 2 means the second layer two mean second layer okay now one it is coming from one is the position uh in this case that it is getting output from one one input that is X1 and it is the second neuron okay this is the second neuron this is second layer and this is the uh the input that is getting from here is the first x one that's why it is for 2 1 2 okay if you are not able to answer notice that is totally fine but let's see that what happens actually to compute this vector okay um okay so how do we compute a vector for this so let's say let's say W12 you have some point eight value we know in the terms of values right 0.8.9 kind of thing or minus 1.7 1.2 kind of thing but we have defined in terms of function to get a better understand so to update a vector let's say 2 1 2 while updating the rule it will be like 2 1 2 minus some learning rate and Delta W 2 1 2. now what this Delta W 2 1 2 is is our interest because this is where you are actually calculating the gradient descent using gradient descent you are updating this value okay so this can be optim uh tell us loss function with respect to the function weight Vector 2 1 2. okay so L is the loss function now loss function can be mean square error or the cross entropy like that so maybe we will start with since we know much better loss function of the mean square error we will take L as a mean square error and we are going to do a partial derivative with respect to 2 1 2 okay that is what we are going to start with uh with now so our task is to update a value we have to find Delta w1212 okay now to find 2 and 2 we have to differentiate the loss function with respect to this Vector which we want to update now if this clear to you let me Define l also that is loss function that is simply uh considering it has only two neurons here that is Neuron 1 and neuron 2 output layer so let's say it has y 1 cap 1 Y 2 cap by 2 cap and Y one cap okay that's the output layer so it will be like I raised to 1 to 2 why is y i is the truth from ground truth and why I cap is the predicted output okay so these are terminologies I am assuming uh it's quite similar and if you try to for this above Network where it has only two neurons what we can do is uh we just expand it so that means y1 by y1 hat uh square plus Y 2 minus y 2 hat Square so we just expanded this part into this function okay so this is a loss function now this is the typical loss function now considering the chain rule that we have seen how we can write it down so this is the gradient that we try to try to identify with respect to the uh Vector uh weight uh weight two one two right so how we can write is okay let me Define one more time here um okay let me write something here pre-activation and activation function okay so in output Vector let's we have seen that this is y1 hat and this is Y2 hat right so upper part let me Define it using yellow this is the final output that we are getting uh after calculating the loss function right but this below 1 which is where I'm highlighting with red this is a pre-activation function so this is like a21 say a22 and this is called a21 okay so this terminology I want you to remember that this is a pre-activation function and above the activation function with respect to it and we have to try to update the weight Vector of w212 okay now what is happening that I know now this this whole function that is if I want to find the derivative of loss function with respect to this two values I need to see what are the immediate intermediate components are here okay so one is y cap another is a12 okay so let me try to Define it mathematically how it look like so after loss function after loss function I have y1 cap above and below in the same same node I have a12 as a pre-activation function right so what I will do so if my bicap is the loss function that is I'm getting certain value right so what I will do I will just write this function as function of loss uh derivative partial derivative of loss with respect to a21 into partial derivative of a to 1 with respect to weight 2 1 2. okay now we can convince with respect to each here that the loss function we are trying to derive it from the preactivation value that we are getting here in the a21 and 82 and after this on top of it we are applying the activation function like loss function sigmoid function or something like that right so we are doing with respect to this so we even if we cut that we can get back to this so This Again is a kind of chain rule of derivative that we are doing again we can mod classify it now in a typical neuron we have seen the bottom half right but we haven't seen the upper part so how we can define it like the same thing this part Square the Box part we can write as loss function with respect to the Y one cap into uh the Y and partial data y1 cap with respect to a21 and partial derivative of a to 1 uh with respect to weight 2 1 2 okay so this is something we had defined for loss function with respect to weight Vector 2 1 2 we are defining finally uh the equation like this this is a kind of chain rule that you are getting okay so what is again is happening you're dividing the main function that you want to achieve the partial derivative you are dividing into Sub sub function so these are these are function one this is some function two and this is function three what you're going to do eventually is you're going to find the values some terminologies of each of this partial derivative put that and and that whatever the values will be there in that some numerical value associated with it so you just going to associate that value with respect device function okay so what those values are we are going to derive as of now okay now so let's start with this so let me write it here again so for finding the weight Vector W12 we have to differentiate it with respect to loss function because I eventually we're finding uh Delta W with respect to the loss function only right so we have defi we have distributed it as Delta 1 with respect uh sorry uh partial derivative of L with respect to the y1 cap into partial derivative of y one cap with respect to a21 with respect to that is the uh the lower bottom half that we are talking about okay and partial derivative of a to 1 with respect to the weight vector this is 2 1 2. this is what these three values if you're able to identify our task is more or less is easy with respect to it okay and uh just to give you just a future better intuition to this what we are going to calculate here the same procedure we look calculate for all and each and every weight Vector okay and there are lot of similarity to this so just keep in mind that once able to understand one part of it that is what we are trying to derive right now you're going to you can replicate the same thing in uh you can replicate the same thing for other neurons and other neurons and other weight vectors as well and biases as well okay so let's try to understand once this simple example how for a when weight Vector how can identify the gradient descent value using this or using the chain rule okay and this is a partial derivative now let's focus on first part of the uh right hand side that is loss function with respect to the Y one cap okay now we have seen that loss function of y1 cap is y1 minus y 1 cap whole square plus Y 2 minus y 2 cap whole Square okay so this is uh this is the loss function that we identify now we have to find the derivative with respect to white one only since therefore this this part will become as constant because here there is no computer of Y one so this no y1 so we will take it directly it as zero so we have to identify now we have to find derivative with respect to this only okay so again let me write it down here so Delta y1 uh L divided by Delta y 1 cap will be written as y1 minus y uh y1 cap whole Square okay now for this example I will just show you again how to derive this part derivative using chain rule okay so how you can do that is we have y1 cap this is with respect to this only we are deriving right so what I will so if you apply a negative function here I will get minus y1 okay so this part I found it now if I have div my again mine subtracted using y1 so I will get this function as y 1 minus y1 cap and then I will apply a square function so I will get y1 minus y1 cap whole Square so I divide the whole this this function y 1 minus y1 cap whole square into three parts okay so let's say Z1 this is called Z2 and this is called Z3 okay now so if you want to write this whole function let me write it down here that is Z3 with respect to dz2 t z 2 with respect to dz1 dz1 with respect to d y 1 cap okay now Z3 is the same equation that we are finding that is y1 minus y1 cap whole Square okay so we are finding this as a chain rule okay so let's do it one by one so dz3 that is Z3 is this and Z2 is this so we can see that Z2 is basically uh we can write Z3 is equal to Z 3 is equal to Z 2 square right because we have taken the one component like this so we can write it as this function as d z 2 square divided by dz2 okay now and dz2 is this and r z 1 is like this so we can write it as d y 1 minus Z1 uh sorry plus Z1 and we can write it with respect to the Z1 okay and finally Z1 is this and y1 cap so we can write D minus y1 cap divided by D by y1 cap okay I hope you're able to follow through this uh chain rule with respect to this if we have any question please type that in the chat and we just look out after this derivation okay now once you do this this now it come down to basic basic derivation now you don't have to put much uh effort with respect to that you know anything of Z2 Square will become 2 Z 2 and here it will be only one value so plus one and here it will be minus 1. okay and if you try to expand it it will be Z2 is YMS 2 if you expand this minus 2 y 1 minus y1 cap okay So eventually d l by D1 y cap it is a is actually equal equivalent to minus 2 into y 1 minus uh y1 cap okay so this is a partial derivative that is you are trying to get it okay I hope you are able to follow that same uh the derivation of a simple uh uh chain of rule of derivative okay you should learn how to divide a function like this into multiple parts and then have a partial derivation with respect to it okay so my mistake it is not D actually it's all partial D so it's not D it should be do it should be function like this so don't take D instead of D you take it as function so because the equation matters here a lot okay so now we got in our quest of understanding sorry so in our quest to understanding this part we identify the first equation now we have to find for y1 hat with respect to a12 okay so let's see what is y1 y1 hat with respect to it now we got for the loss function with this y one hat now what is y1 hat here so y1 hat is basically a typical sigmoid neuron okay so uh or we can what we can do we can derive it properly right so let's write it as okay let's see what is y1 hat from the equation the this thing itself let me erase this yeah okay so what we are finding is y1 hat okay it's a combination of the output that you're getting here this one okay y1 hat is a combination of a21 and a22 the desserts preactivation function with respect to it okay so here we have this function with this A1 a21 and A2 okay why uh because it is uh because when you're trying to find as a probability distribution what we do is we try to find the value in the terms of probability distribution as a21 with respect to the summation of all the all the values that you're finding a with respect to A1 and a22 that's how we find the okay let me look out the terminology exactly what I am trying to say here that will be much better for you to understand it okay uh okay so just give me a minute I will just tell you the exact terminology I'm looking out for um yeah using softmax function so this is a soft Max function eventually this is the word I'm looking out for okay so what you do is if you're trying to if you have seen the field forward Network and the last layer before applying the loss function you do something called as softmax function so there are y1 will y1 cap will be equal to e raised to a21 using with the actual value through which it is getting affected divided by E raised to a21 plus a22 so this is a soft Max function okay so this SoftBank function is equal to y1 so now our task is to find a y1 cap partially of a by one cap with respect to a21 okay and our a by one cap is basically the soft Mass function of with respect to a21 into a raised to A2 okay now we have this as a function and our task is to find the second terminology with respect to the weight Vector that is uh a y 1 with respect to a21 okay now we have to find this value as it is so let me uh Define it how you can write the same equation as it is so what we can do for our convenience uh let's get it into a simple sigmoid format how we can do that we can do a raised to 2 plus e raised to a21 e raised to a two one Plus e raised to a22 and what I will do I will just add two equations here that is I will divide and multiply multiply and divide by a raised to minus a21 okay so I will just divide and multiply 2 this is for our basic convenience to convert into a better format so once I able to do this I will get If I multiply this I will get the value 1 so numerator will become 1 and If I multiply this one with this I will get it as 1 as it is and it will become a raised to minus a22 a21 so if you have seen this equation it is something equivalent to sigmoid function right it's equivalent to sigmoid function and we are going to utilize our understanding of sigmoid function to derive it okay because that will give us better and starting with respect to it okay so let me quickly do this um so so D now equation will become a21 so how you can Define it as is if you want to write this as a chain function I will just tell you what is it after that I will just write the actual answer so if you want to derive it as a chain two you can say because it's a21 right so after a two one you will multiply with minus a22 so this function will become Z1 is equal to minus a22 a21 okay so this term we have found now after that we'll apply a exponential function so that will become Z2 is equal to e raised to Z1 okay after that we'll add one so they will look at Z3 which is equal to 1 plus e raised to um 1 plus Z2 okay now after this we apply inverse function and we'll get it as y1 cap is equal to 1 plus 1 by Z3 So eventually we divided the whole equation of this this equation of 1 divided by 1 plus e raised to minus 82 A1 1 into 4 different parts and if you try to take individual derivatives of this with respect to uh d y 1 cap which is put 8 Z 3 that is Z3 then dz3 with respect to dz2 dz2 with respect to dz1 and dz1 with respect to d a two one if you do this the final output will be um will be like let me write it down here first here so y cap with this would do a21 will be like I'm just starting down that uh this thing Z 3 Square into e raised to Z1 into minus a22 okay now if you try to expand it if you put all the values of Z One Z to Z3 you will get a very big expression okay now let me write that also to get you a better understanding so this minus minus will be cut off e 1 plus e raised to a22 a21 this is square so I'm just taking one equation here e z 1 is also same so e raised to minus a22 a two one divided by 1 plus e raised to minus a22 a21 plus a22 say minus A2 okay now this one is basically a y one cap this one that we are finding here this one is actually equal to y1 cap right that's how we have defined it earlier so let's so we can write it as y1 cap the whole equation we can derive in terms of y1 cap and minus a22 so this is what we got with respect to dou of a21 y1 cap this would do a two one so all this equation come down back to this uh again back to some simple equation that is y1 Cap into 1 minus 5 1 cap into a two two a two two is the activation value whatever we get it through the when we are putting the values okay now the last part remaining in this um okay I hope I can't add it new okay uh let me write it down okay so last part is this uh let me write in different color that will be better that is d a two one with respect to d uh two one two okay so we have seen here so this part is also done now remaining is a21 with respect to do one two one okay so this will come back to so how a21 is actually defined that is we have to see now typically a21 is defined by the weight vectors let me go up again a21 let me take below okay yellow okay this a21 will be defined by all the four neurons I am trying to highlight with yellow if I hope you'll be able to see if uh let me change it to Blue better so I'm highlighting with blue so all the A2 and the preactivation function will be depend on the all the neurons from the last layer okay so how we can write it down as we can write it down as a21 which is equal to the weight Vector of previous layer that is a221 something has happened yeah a21 will be dependent of weight Vector of the previous uh from the lower layer that is one and the activation function from the lower lower neuron similarly in 2 1 2 1 to h12 w213 h13 Plus w214 h14 so in a simpleton what I am trying to say is this a21 is dependent on the H value of the Hidden layer that is here h14 h13 h12 h11 and whatever the weight Vector assigning to it so it is like a two one one two one two kind of like that so all these vectors are depending on this a21 value that's how they are dependent okay now if you now if you have observed right now we are trying to identify that dou a121 with respect to w212 because this is what we want to update right so accept this all the other functions will be considered as a constant so we will get it as 0 0 0 with respect to this only we have to observe only these two values only that is with respect to w212 all others will be acting as 0 in terms of derivative so when we try to derive it it will become as H 1 2 because it will directly calculate and this is also considered as a constant so it will be become 1 and H 1 2 will be remained as a constant ah constant value as a final this thing now to summarize what we have find from all the derivation of the one vector so we have done all the derivation for one vector just to get this value loss function of loss function with respect to weight Vector 2 1 2 from where we're trying to update the value right we divided to three different functions and if we try to pull it all together it will be like minus 2 y1 minus y cap into this is for the loss function with respect to y1 cap with respect A1 will be like y1 cap into y minus y 1 cap minus a22 into h12 okay S12 is coming from this so h12 from here let me highlight with green this box of which I am highlighting ring on the left right hand side is coming from A1 deriving the y1 cap with a two one and the above one the first equation we are getting from the loss function with respect to y1 cap okay so in this half an hour of deviation of 40-50 minutes of derivation we have found the derivative only for this value now we will get we will easily available for y1 cap and and a to 2 and H these three values we can easily get it when we try to substitute any function okay what are the weight vectors and everything is happy so once we get that value we just need to substitute in this equation what we derived and we will get some value with respect to the Delta W okay we just need three value y1 hat A2 to a 1 2 to update the value uh to get the Delta W value which we again going to post in Okay so which we are going to post again in W1 are w212 which will be eventually we'll use for updating the weight Vector 2 1 2 okay uh if it is going little above please let me know uh but the context is if you're able to understand that how you are using partial derivative with different functionalities to get a certain values which you will get in the terms of this that you have seen in the above that is A1 H1 y1 cap by 2 cap in this function these values will be numerically you will be given to you a model can be given to you but how to update even simple value of w212 you have to do a lot of derivation with respect to it the aim of this derivation or partial derivation to to help understand that the updating of weight through a loss function not only depends on uh just one single value of neuron the lower neuron to the upper neuron but also on the surrounding values all the other neurons that you are having and the hidden layer will affect the calculation of the w212 weight if that this is the kind of intuition that I want to give you through this uh or try to convince you through this uh derivation of updating one single weight similarly for other weights also when you're trying to update a value it's not only dependent on the neuron and the weight but also surrounding neurons and its own weights as in their respective weights and biases as well okay this is what I am trying to convince through this derivation Okay so let's take a break for 5 10 minutes maybe try to see uh I will share you all this sheet what I am doing right now I can't share it online just like how you can do for collab but I will try to share the same sheet uh once this is uploaded I will do that okay so let's take a break for 5-10 minutes and uh no let's take come back by 7 15 and we will I will try to give you the way we have updated for two one two one vector how we can do I will just give you intuition rather than derivation or how you can do for multiple paths like how you can this is one even for some single weight update you have to do lots of calculation how you can do uh in the case like this where to update 131 you have to take two different paths so how can you do that this is what we are going to discuss so one question is do we calculate loss for each output neuron separately yes so once okay so uh I will give you the intuition maybe after this part that why do you need to calculate loss for each output neuron that is uh that is much better that will give you a much better understanding even because in a multi-class classification uh binary it is okay you find for one loss you can automatically by minus when you can find the loss of another neuron but in a multi-class classification you have to identify for a loss for each and every new output neuron and how it will you have to trace it back to the input layer you have to test it back to the input layer and then we have to again calculate based on the values that you're getting with all the derivation you are finding it out okay okay uh okay maybe I think it may be little math heavy just bear it for maybe 10 20 minutes uh with respect to it I will give you this for one more intuition with this book how you have to do for the cases where you have multiple paths I will just give you proper intuition for this after that we will see the code and that's how we will end the session okay so by 7 15 please come back here thank you foreign foreign foreign so at least in the last one hour we have seen lot of derivation and lot of uh derivation with this book to how you are breaking a single function into multiple Sub sub functions to get a final output and that's on those sub functions you're doing uh a derivation on top of that says that your job will become easier right uh at least you have to summarize for last one uh R what we have done is just to get you a con I just wanted to convince you that uh you might heard the term in a more generalized spaces that I can give you more better than this thing that the Deep learning that you are doing you know it's kind of kind of black box if you have heard the term black box with respect you don't know what is actually happening within the system right how it is learning it so if you have used charge ft around you don't know exactly what is actually happening how it is able to give me a much better uh answers with respective so lot of uncertainties with respective is present here right but now what you are actually trying to see that if you want if you actually want to understand it you can explain many aspects of the deep learning model but you have to go by very it is very complex in terms of this function that even for updating one single Vector you have to do two three page of derivation you have to be very brutally honest with respect to it and you have to you have to take care of multiple factors that is something called as A2 and that is pre-activation or the activation of the previously here right the weight vectors of the from the activation to the the node a neuron in the which we are through which we are concerned about so lot of computation happening only for finding the weight for one updating the value of one vector so let us assume that in this in this uh simple a neural network itself you might have three uh first to for 16 16 into 8 like 24 uh 24 weights so for each and every weight you have to do proper derivation this protect finding adjusting the values into that and you have to do a lot of computation with respect to and this is very simple right the more it become big the more is harder for us at least for human to get a grasp of how the updating is will actually happen right so that's why the conserved black box has come to which you don't know the how model is learning but somehow learning right and this if you can get a little bit understanding that you are doing certain partial date differentiation you're being applying certain chain rule with a spoon derivative which involves multiple components which is book to its own layer and the previous layer content okay if you can get that aspect you can understand that how the gradient isn't working to picture on updating the weight value the same process will go for biases as well okay so my task is here to uh get to you intuition that the blacks box which is actually coming to picture is actually a series a lot of computation which is happening in the background which you don't have to take uh care about usually it will be taken care by directly by software the tensorflow and pythost library but you should know at least some intuition what is actually happening in the picture behind you might not need to know the values and all but you should know the process behind it the process is something that we have seen right now in the terms of partial derivation of one weight Vector how our weight Vector gets updated right so this is the kind of con I want you to convince with this fact that lot of computation is happening just to update one vector for one Epoch so when we are saying that we are running a model for 200 box 20 approx 100 epox kind of thing each we're getting updated 200 300 times and in single updation lots of competitions happening so that much of high amount of computation is happening and that's why deep learning models are so much uh heavy computational resources okay it's it's not something we can say that it just happened like this lot of derivations happening in the picture a lot of combination happening to picture because of of lot of this thing that you are seeing just now in last one app okay so I want you to convince with respect to this another point I wanted to convince that for one vector for one vector updating you have seen one simple line right that from should find w212 you just have from one hidden layer you have to go to the output layer right so this is easy to maybe easy to grasp with respect to the that even for this you have lot of computation but what about uh layers where you you might want to go to the output layer but you have lots of hidden layer in between so let's assume this w131 to update this Vector of the weight vector or weight value of w131 first you have to go to the first hidden layer from first hidden layer you have to go to the output layer now output layer will have two neurons so you have two parts so you have because you have to update with respect to this one so right now why you have had two paths that is the first question that we can naturally ask for the reason of two parts is now I can see let me okay yeah now I will say based on this I got some loss function value okay I got some loss value now I will say that okay who bring me this loss okay so I will uh so the y1 cap and Y2 cap this on this neuron they will say that I didn't bring this loss I I got what are the loss function value you got is because of the value of a21 and a22 because these are the inputs I had taken as as an input and whatever the output I am calculating using soft Max function I'm giving you okay so based on input I am getting the output that that tier definition of Y and uh difference of y1 and Y2 cap now now you will ask that okay why you are giving wrong input to the you will ask this you will ask you will term them accuse that a21 A2 a22 are not giving correct value so you will ask them then what do you what they will say that no no this is not my fault I am getting whatever I am giving the SI input based on the weight vectors of W2 weight vectors and the H1 uh H1 pre-activation functions okay so these These are n plus bias so these are the inputs whatever the inputs I am getting from W2 uh W2 and H1 that is W 2 1 W 2 2 W 2 3 kind of like that and H1 h2s3 for each of this neuron whatever the values I am getting I will I'm adding with the bias and I'm giving you this so you should ask this weight vectors and H1 so they will they will try to defend themselves like this now again H1 will say that no H1 they will say I am a sigmoid neuron I'm a sigmoid neuron and I am also getting input based on the values of A1 ah preactivation function that I am getting that's a one um a one one a one two a one three kind of like that okay so you may again ask them that why you're giving me wrong input then you will go back maybe go back down to W1 that's the initial layer of from input to First hidden layer and they will say that okay yeah this is chance that I am I'm giving you wrong inputs uh so please change my value okay so that's how you're getting you're trying to deduce it try to Define it from where it actually might get wrong okay so that's why you're doing this is the concept of back preparation coming to picture so from here one from one neuron you try to find that okay for two to get to two one three one I need to find the value from here now I will first accuse this third neuron the first layer and I will say that okay you're not giving me correct output give me correct output then you will say okay I am also getting the output from w31 so I will Trace back to W 3 1. okay that is the one way of accusation you can find it all that's why from output layer to go down to the third layer a third neuron on the first layer I have to trace it back okay because one three one is into the quotient that now I have to find out how and why one three one um can be updated or can be improved because identify that one three one is the accused uh and it's not giving me current put now it's my task to update this value okay so how I can find it so again the concept is similar to what we have seen earlier that now I have multiple path into picture that is from X1 uh to third neuron w31 is there now from third neuron I have to go to y1 cap and I have to go to Y2 cap so I have two path available that is one leads to y1 cap and one leads to Y2 cap okay so I have to compute for both of this thing such that I because it is it is giving me wrong value and y3131 is the accused one which is not a which giving me the wrong input right so I have to calculate for both the path so how can I do that so um let me write it down here so when we are trying to find the uh find the value with respect to the any weight Vector we have found to update it so we will say that W1 if I have to update I will say w131 minus learning rate and W Delta W one three one okay and my interest is finding this Delta w131 which is basically we finally using gradient descent so this is the gradient descent we found so how we find it we write it as that to improve the loss function since my culprit is w31 so I will Define I will try to derive uh Pi I will do a partial derivative of loss function with respect to w131 now I know that it's not easy because lots of in between function come into picture and this is the kind of focus I want you to bring in to find the multiple path now you have to divide into multiple function I will say that that the loss function will be divided into a13 into a13 W one three one what do you do I mean by that so I am saying that this is this value the third neuron is a has this value of a13 so first I will try to derive the loss function with respect to a13 and I will derive then I will take a partial difference of a13 with respect to a W uh partial difference W one three one okay now this is something I can find it directly easily okay but I need to focus now this can be further divided by because a13 again will get down to h13 and h13 will again get down to a21 and a22 so multiple functions are coming to picture so what I will do I will again split this function to multiple functions so what I will write it as that a13 from a13 I am getting to two different parts that is um a h13 and let's say ah13 that will be much better and A1 h13 by Delta a13 and a13 w131 so this is as it is I am writing it off now what is h13 h13 is my h13 is my okay I am highlighting it right right now in the third neuron that is the activation function so h13 is my activation function from there till now I am here now from here I need to Define these two values for a 1 a 2 1 and 82 other output layer neuron so to do that I will divide again this function into multiple paths so let me write it down here let me take black again so I will write it down with respect to Delta uh loss function with this root a21 and a21 with respect to h13 and and a 2 2 and partial a22 into a22 by h13 and the rest terminologies will be same like a 1 3 by a uh partial differentiation of A1 a13 h13 by a13 and partial differential a13 by weight Vector 1 3 1. okay now this is something I'm going to identify this is my two pass that I am talking about if you try to expand it you will get the same value okay now my focus is on this this underlined part where I am getting multiple paths so if I have K paths that is if I have output like K neurons so this this partial derivation will become into plus K that is uh more equations or partial derivatives will come into pitch okay again I'm I can again try to substitute them and I can mode uh break them into more smaller functions so let me write it down one more time so I can write it right with respect to y1 cap and I will derive y one Capital to uh dou of a21 and a21 into h13 okay so what I have done this function I've wrote it like this okay this function uh the first two equations the first two function that I have written I I just derived this into this I just expanded it because this is the lowest level I can get into okay and the similarly for Y2 cap also I'm trying to do it um so Y2 cap by a22 and a22 by h13 Okay so this equation I have just derived it from the the second neuron that is y y two cap so I just Define white one cap and Y two cap here and this this ah two terminologies will remain as it is here okay so let me just for the sake of completion let me write it down that is dou of h13 by 2 of a13 into a13 dou of a13 with respect to dou of w131 okay so this is the equation that uh this is partial derivation you have to find now put all the functions of Y one cap a 1 2 H 1 3 into the picture and you will get some values okay so this is what we can again the whole derivation will come into four five pages of what we can do for identified W 3 1 for updating the weights okay now what the kind of take I am suppose you are not able to uh able to understand this and you still finding a little more hard with the smooth derivation function so what are the kind of takeaways you can take away from here so that will be much better to give you this so what one thing you have to take into picture is that no matter how a complex function is so this is if you see this this whole big equation and the above you find a lot of parameters into coming to picture right lot of partial data we have to take it on to the picture so the kind of complex function is there but interesting take is we can always divide this function to Sub sub parts so we can always compute the derivative with respect to any variable using the chain rule so as a first first takeaway for you so whatever actually updation is happening that is what we call as gradient descent add-on where multiple parameters committee that is a21 ah13 a22 y1 Cap by 2 cap right w131 that too with respect to aiming where our aim is to find basically updating the weight Vector 131 with respect to loss function in between this this thing only we have found such a big equation all this thing can be computed simply using the chain rule that's the first takeaway okay now second takeaway is now let's assume that I have already computed let me clear the screen here once oh okay let me take different color better um yeah that will be better okay now let's assume uh I have already calculated this part okay now I have calculated for w31 now let's suppose I want to calculate for the second neuron in the uh second neuron the first hidden layer now again I have to come back to this first output layer itself right I have to compute a21 a22 H2 uh h21 s22 kind of thing right or y1 cap by two cap so already computed this using some equations okay I do need to compute it again and again and again what I can do is once I have found for one typical layer I can just substitute this value while Computing uh the Val values or operating the values of any weight Vector associate with the second neuron right similarly let's say I have multiple hidden layers in between okay so let's say this is input this is output and these are the hidden layers what I need to do I just need to certain important functionalities or values of this output layer keep it safe in some variable okay whatever the values I will have and then whatever because we have permutations a lot right because each neuron is connected to each other these are fully connected so all the input layers are connected to all the layer number one and layer number two so all are connected to each other so they have multiple permutation combinations coming to picture so you can't take it for each and every again derive it again calculated what you can do is I have found certain values already during my first two iterations first few iterations with me store the values somewhere and I will then compute I2 when I am trying to let's say I'm highlighting this using red now let's say in the second second layer first neuron what I will do whatever the values I have computed for first output layer I will take it as a byproduct because it will eventually come into picture and I will take it and store it and I will try to compute it so again I don't have to compute it I will just keep take it from the pass thing and then I have to compute similarly let's say second you're on the first layer now I have to go through this so what I will do I already calculated this part I already calculated till this point so I will do I already I will take whatever the value I am getting from here and I will use this value to um use that very store value to compute my next set of iterations to update a particular vector okay so second takeaway with respect to this is while doing lot uh if you do a lot of practice with respect to derivation and all that you can find that we can use or reuse lot of work by starting backwards basically because in back propagation The Reason by back propagation is more important is we can use lot of these values what we are computing and computing simpler elements in the chain okay so these are two takeaways you try to get it from this that will um that will be much better that is the complex will become uh the function that you're going to see in in the next few more upcoming this thing uh conversion Network or recurrent neural networks and other um Transformers and all that right more complex function will come into picture with the basic fundamental factors that you can have when trying to update a vector when you try to update a vector you have to find a gradient descent or maybe some other vectors vectors to that for that you can always need to use the partial derivative and to do the partial directory you have to come decompose the function into multiple smaller smaller functions okay any complex function you can derive into simple simple function using the chain rule that's the first intuition second tuition is when you try to compute all the stuff it may look very cumbersome or very calculative and all that but there's always a chance of reusability with respect to the values that we are calculating okay even after this also it becomes little bit complex when we try to actually train a model because here we are dealing with four five or six neurons but an actual deep learning model when you're trying to build it you will be dealing with hundreds on Euros 200 300 kind of neuron right complexity with this input data will change a lot right there you can't keep track of all the stuff but you will you try to get you'll get an intuition that okay for each neuron this is how my weights are getting updated this is the pro complex um complexities come coming back to the picture that's why it is taking a lot of time so when we say it is taking a lot of time for each Epoch or it's taking a lot of time with this book that the reason is this much amount of computation that we have seen as of now like it comes into handy because lot of combination the computer has to calculate off right that's why a lot of mathematics come into picture to understand to make you understand that why deep learning is so complex with respect to when we try to deal with it okay so that being said this is uh the kind of back propagation we have seen that how our updation of weight using back propagation has come into picture to summarize in a feed forward Network in a typical feed forward Network you start at the bottom you you have certain weights which is pre-initialized okay as random so it's a kind of random initialization based on that you have something called as pre-activation and and there's something called activation function right so you will compute all these values and let's assume that all these neurons are typical sigmoid neurons okay so all this function will come into picture and you you calculate all this stuff and once you calculate the y1 cap and Y2 cap let's assume this is a binary classification you get some loss value okay till here the feed forward will come into picture everything is fine now the back preparation computer picture where you try to identify why this loss is why this loss is coming here so what you will do what what you try to do here is that you will try to trace back foreign of giving me such high loss function so from there you try to trace back and see the all the uh from the places from where you're getting a different kind of uh values to till that point right so you trace back here so that's tracing back using the partial derivative and the chain rule of truth will come into picture and you try to find that okay maybe from the starting of the weight vectors maybe from here I need to start changing so I will Trace back and I will update my weight vectors accordingly then again this again this feedback loop again will come into picture feedback now feed forward Network so once my vectors have been updated using back propagation again from the lowest layer again I will start Computing Computing Computing Computing I will go to the end I will find again the loss function that is so that we are getting is a one Epoch so in one Epoch you're getting forward tracing back if after one Epoch you find some loss function you trace back you find a Delta W and Delta B and that is grads with basically green and that we call as we find the gradients once you find a gradients you update to all the weight vectors again in the second Epoch you will go you will again go back from the bottom you will calculate again you'll find again the loss function again back Trace again see that where you can update the way um weights again go go back so that's how the epochs are happening in the background okay and that is a kind of basic mathematical intuition I'm trying to try to give it to you uh please practice it just to get to get you convinced of uh yourself that whatever you're doing is not something backwards it's not something randomly happening in the um in the in the background scenario lot of computation is actually happening and it has some mathematical base of fundamentals of why certain weights are updating of certain weights or certain images or any problem that you're trying to give how it is learning it is coming back to the fundamentals of uh partial derivatives and the chain of rules with respect to that okay uh now what I will do is I will uh just let me open the the code which I want to share you with and which you can play out typically says that uh we can see that how uh how you can play with it and how each and different vectors you can play with okay how what is the importance of each Vector activation function then activation function plays a role while learning a certain kind of uh role was while learning a certain patterns and all like that okay so let me stop sharing the screen once I'm loading it uh okay let it get connected in the meantime I'll just close the screen okay I'll just explain you the code I will just share it let me share the code as well I am putting that thing in chat okay now okay so I hope you can see my screen as of now okay so what I'll just go I'll just go through it so maybe later you just try to read it slowly slowly and try to understand the chords I'll just give you prop overview of how the things are happening okay so if you have seen the last class we have generated certain class gendered data and class uh with the points and we have colored the data with three four colors with respect to that and then we will see that the impact of one single bit we just change one weight in the vector and the whole uh Network and see the how it is impact your accuracy of the whole network okay and we will visualize it then we will try to see in the proper larger networks where we are updating going to update each and every weight and we'll see that how it is impacting it okay so the code is all written it's running so you just need to maybe try to run it and maybe try to understand line by line so first this thing is basically updating uh importing all the necessant libraries this is the customized for matpod relief thing that I want and this is a random seed with respect to this okay so make a random data generate a data we use a function called May blob uh make blob underscore block where we are taking 100 samples and uh let's run this so and it has four we have divided that hundred thousand samples into four different colors okay so there is green light green red and orange kind of stuff so this is a four class and our task is using feed forward network with the helper back propagation which you are already doing it but let's now make it more explicit in the terms of scale Up drag propagation okay uh there's something called vectorize back propagation as well we will maybe see the another another session so what our task is the feed forward uh for multi-class classification we have to define a kind of line to separate all these four different type of data so before doing that let's start with binary classification so what we are trying to aim is so let's before going to the four classes let's go with the simple two classes where we have the right points and we are going to divide uh this red points and Green points into two different classes okay so that's our objective so we will train using train test split and we get that 750 values for training and now 250 value for testing okay now this is our first uh feed forward Network where we are initializing simple weights so we have three neurons ah Sigma neurons each neuron has three biases okay and considering we have we need only two classes so let's say X1 X2 okay so for each neuron it will have two inputs that is W1 W2 for neuron one from X1 X2 w3w4 for neuron 2 from X1 X2 and then and this neuron this neuron from for first four weights is the hidden layer and the output layer will be has two neurons that is either red and green for where the weights are W5 and W six let me see I can show this thing or not okay so this is the basic uh this thing uh the the try to we represent is the three neurons H1 so you can see in the red color we have two inputs X1 and X2 we have six weights W one W two w three W four W five w six and three biases so this is a basic neuron structure we're trying to make it now our first task what we have done is uh in this first set of code okay we have defined the forward path that how the value of H1 A1 will be get updated and how the you can get the final output and how you get the final output in terms of file but now when you're trying to do a back propagation in this case that means you're again once you find this value and you will get some loss function so our task is to update only one vector so in this case what you say we will update only one vector that is W1 that means out of all these vectors from X1 to uh neuron 1 this only we're going to update W1 and rest of the weights will keep as it is we are not going to update it so you want to see that how it is going to help us in reducing the uh improving the accuracy of the model okay just we want to show see that so instead of putting all other uh ways we just updating only one vector and it is getting some through formula through derivation so let's assume that this is a proper formula if you want to see you can get back to the overlay lectures where we have derived this part okay now these are something all set function where the whole learning learning part is written that once you call for once you call for forward pass then you will do the apply for grad function that is for calculating updating the values and then you operate the W1 Vector only rest of them will be keep as it is and then this is a code for displaying the output okay and this predict function which is at the end can predict it so let me run this so what we are doing we are initializing one uh based on the above Network where we are just updating W1 value we're just calling initializing one FF new and W1 as our object and we are calling for fit where we are going to train this model on the data of binary classification data we have seen earlier green and red dead and green points for 500 blocks for learning rate of 5 and we are displaying the loss okay so we are displaying the loss so let's see what the output we are getting okay so we have plot two different plots so I think this one I have to adjust but the x-axis is the epochs and in the two this there are two y-axis are there the N1 is W1 so we are trying to see with respective work how the value of W1 has been changing that's the first graph the topmost graph and the bottom of graph is with this how how the loss function is calculating in this case mean Square okay so if you can see that till maybe 100 or 200 kind of thing 250 uh epochs the weights as we uh decreasing from 1.78 which might be randomly initialized till one point with less than 1.3 right after that it is getting converging that is it's not updating now the same thing we have seen here also that for mean square error after maybe 150 epochs the mean squarer is not getting updated so what the major point from this graph you can identify that even though of weight we can okay first conclusion is that updating the weight W1 is improving us to uh is helping us to improve the accuracy that's the first part that how we can say that it's improving accuracy because it is um lowering down our loss function value right but we can also see that the values of loss mean square error the loss function is not that drastic so that is from 0.232 from where it's starting to 0.229 that is 0.00.03 updation is happening so even though the weight value has been increasing to 200 reports the loss is not that much in a decrease so it has some uh W1 has some um what's influence but not to that extent so that is one way you can see it out and what you can do is after W1 maybe you can change this part of the code I'm highlighting right now in the grad where instead of W1 just type 2 for W2 w3w4 and see that influence of each individual weight vectors on the loss function the effect of changing the weight Vector on the loss function you can try it out okay so this is the first point now what we're doing right now is let's do it for full uh class uh now what we do we will do it for whole networks we are going to update all the weight vectors and all the biases earlier we have done only updating one weight vector and all the other biases and weight vectors we have kept at 0 as a constant value right we haven't changed anything but here we are going to change that is a typical feed forward network with that propagation now this is the grad or Delta value that we are finding and this is derived uh using derivation so we have written like this okay so we have run this thing and we are updating uh initializing this some random value and after each Epoch we are trying to um find finding the W Delta W Delta B values and updating the weight vectors and the biases respectively and we are showing the display loss okay so you can slowly slowly afterwards you can look at this code and you can try to understand it what each line every means is but I am just giving you overview with respect to that now after this is still here everything was typically normal that we have seen from last two three uh live coding sessions but here we are doing something else as well what we are doing after predict we are also trying to see the effect of H1 H2 and H3 so what are H1 H2 S3 H1 h2s3 are basically the activation function of all these three neurons so we are trying to see that we are trying to store the intermediate intermediate value of H1 h2s3 and storing an array and we'll try to see that how it is going to affect our accuracy or the loss function with respect to it okay so we are uh so while storing the values of H1 H2 S3 we are just making a list and we are putting uh we are trying to see the influence of H1 on the Y predicted value and all and we are going to show it uh we're going to visualize it for the basically for visualization so we want to see the impact of activation function on the accuracy of the model or training the model with respect to this how better it is influencing us okay so that's the purpose of this code and we are trying to fit this with 2000 running in perk learning rate is pretty high that is five uh and we are trying to show the display the uh the loss as well as displaying the weight so let's see what it will do okay so what okay it is showing only one thing ah okay let me go down to better here also right okay so this is the first graph that we found that uh it's a typical graph of mean square error with respect to a block that is till 500 it achieve a particular pretty good means loss loss value that means our accuracy will be much better now we talk about the we have to see the influence of H1 H2 and H3 so we do that using mesh grid product Contour plot boundary okay this particular for visualization so just let me just run it instead of explaining the code I will just show you better so what what we want to see is the value of this H1 h2sc these are activation functions okay we want to see how it is has one how each neuron is affecting or creating a decision boundary okay so the first graph is for H1 that is the first neuron in the neural network and we can see here some kind of yellowish line here if you can see my pointer are moving so this yellow line is trying to separate the uppermost green points with the red points here this is the first H1 H1 neuron is trying to do H2 neuron what what is trying to do is is trying to separate the bottom green points with this book to the red points that is a this there is a second neuron trying to do what third neuron trying to do is is trying to uh combine both the h1s2 output and try to create a much more better boundary lines for separating the red and the green points okay so what you can do as excise maybe increase the neurons and on and try to see that how each and every neuron is affecting the decision boundary lines and if you can observe here the width of yellow lines here and in H2 and H1 is pretty big okay but in H3 it became very compact or small size with respect to the the other neurons so we can also see that that uh when it comes down to the output layer of neuron it combines or condense all the noise that they have found um during their competition to give a much better output that's suspect to it okay so this visualization tells about how each and each neuron is playing its role in finding the decision boundary for separating the green and red points so that is the code with respect to it so please check it out with this book do that now we are going to plot another visualization that is to show you that okay we have seen for each and every neuron right but what we want that we also want to see that how with each Epoch the weights of the each weight vector or weight value and bias are changing so for that this is the code that we have written okay so what we have done is for uh since 2000 epochs are there for after every uh Epoch we are trying to update certain values so how to read this value so to do that let's go up a little bit give you better understanding so in this image to visualize a matrix this is how we are storing it so the second row if you can see so for each neuron we have three values B1 W1 b w 1 and W2 okay so that's how the weight vectors and biases are being adjusted so here also visualization wise B1 W1 W2 uh for uh neuron one for neuron 2 is W 3 W ah 4 and B2 and this is a hidden layer and the output layer is uh B3 W5 and W6 okay so you just look at this image what are the values are here and just try to map it out with this value so obviously the first uh first row First Column and the last uh the last two uh Columns of the first row are zero because no values we are not reaching those values we kept it as zero okay so this is the kind of we call it as heat map okay the lower the value uh so it Define a range from that means if it is positive it is green if it is medium is yellow and if it is less very less value it is shown as red this is called heat map so if you can observe maybe after spending some time how the values of weight vector and bias changing after each and every 40 box okay you can see also for you reduce the number of epochs and you can see for each and every box as well okay so you you can do that and you can see the values here if you can see the fourth column here how it is started changing from yellow and orange to Red so earlier it was minus 1.1 0.001 which is near to 0 and how the value are changing to very uh red values that is it's decreasing it by 2 minus 4.4 minus 2.2 kind of like that so if you keep on changing this weight vectors and biases over the all the epochs and you can see that after certain box the value will became uh the values will not be changing as frequent as we have seen earlier that means it's trying to stabilize it trying to converge to a particular values this is one kind of visualization that you can see and try out for multiple these things okay uh this code which I am highlighting uh if you try to run it on your local system you can get a proper GIF of all these things stop printing out you can get a whole GIF of that okay uh in Google collab and the functionality is not available so that's totally fine so whatever the value we have get the our model train accuracy is 0.98 and 0.94 which is pretty good okay and this is how the final output look like all right okay this is how the final output look like the same process we have applied for multi-class classification as well where we have output of 4 at the same points as we divide into four different classes so that's where the output layer is for hidden layer is two layers and we have input of X1 and X2 okay and this is how the output layer will be look uh the epochs that we have seen earlier in the terms of heat map this is how it it will be arranged okay so same code you will write it down here and you can run it and you can see it all yourself but I will just go for the output as of now um is updating the ways and all the stuff that is totally fine in this multi-class classification we have applied softmax function and the log cross entropy as a loss function okay so this is the log loss on the y-axis and the epoch so with this 50 perk how the cross entropy loss function it is actually decreasing over the period of time this is the one thing and to see the weights instead of now looking at each neuron we are trying to directly see the weights because weights are of more interest to us and we can so we have defined this epoxy with this book to each and every 100 epochs what is the condition of Weights okay so you can see that how the weights of values are changing for multi-class classification okay and and when we try to do for multi-class classification we have get a accuracy of 77 percent which we can increase it with with the modification of hyper parameters of learning rate and epochs and all that like that and the final output is something like if you can see the big green small green dots or small dots are means that they are correctly identified by the model and the Big Green big dots of various colors has been considered the wrongly identified okay so this is what its final output look like so I want you to play with this maybe understand it slowly slowly one by one I have shared the link already in the chat box um so maybe try to change it change the number of epochs see the values of Weights that in the 1900 weight the if you can say first row and first credits minus 8.7 but if you go by the zerothy park its value was minus 0.16 so how from 0.16 to 0.18.7 it is going so that means the value of this bias has been very influential to the model training so wherever you can see the dark uh color that is green and red there you can see that it has influence a lot in the model train those values has been influenced around in the model train those are where like yellow or very light color in race like 1.1 1.3 they are not that much influential influential to that that's so so that's another way of reading that's this quote or this understanding okay so as of now I know I have run through the code very quickly but I want you to First go and see the code run the code and try to see how it is actually impacting uh and how it's impacting how new each neuron is impacted and how each Vector is weight vectors and bias are impacting so I want to try try it out maybe by next session if you have any doubts with this bill's code I I can explain it okay so in summary what we have discussed is uh let me just a minute so what we have discussed is the mathematical intuition of how updating a single weight Vector includes lots of complex computation but we can do it more simpler Way by dividing a complex function by dividing into much simpler functions and then do a partial derivative on top of that and any complex function can be divided into simple functions okay that's a first takeaway second takeaway is that even in that complex function there's a lot of re reuse component will be present so which we will use it to calculate our the complex all the complex functionality that we have all the completion we can reuse a lot of number of times okay now followed by the code where uh the code in which you can visualize the impact of the neurons as well as the weight vectors so that is uh you can visualize it using that code please try spend time on that code try to understand it if your notification please get back to me in the next session okay so if I have any question please let me know otherwise the this thing is n from my side the session is ending from my side thank you very much foreign okay so in that case I am ending the call if you have no one has any problem so let me stop the recording once

